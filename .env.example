# Ollama connection settings
# Set the host IP or hostname where Ollama is running
OLLAMA_HOST=localhost
# Set the port Ollama is listening on (default: 11434)
OLLAMA_PORT=11434
# Set the Ollama model to use (must be pulled on your Ollama instance)
# Examples: llama3.2, gemma2:2b, mistral, qwen2.5, etc.
OLLAMA_MODEL=gemma2:2b

# Brave Search API settings
# Get your free API key from https://brave.com/search/api/
BRAVE_API_KEY=your_brave_api_key_here

# LangSmith tracing (optional - for observability)
# Sign up at https://smith.langchain.com to get your API key
LANGSMITH_TRACING=false
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=f150-expert-agent
